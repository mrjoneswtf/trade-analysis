{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Data Cleaning & Harmonization\n",
        "\n",
        "This notebook cleans and harmonizes raw USITC trade data for analysis.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Load raw USITC data files (wide format)\n",
        "2. Transform from wide to long format\n",
        "3. Standardize country names\n",
        "4. Apply inflation adjustment (convert to real dollars)\n",
        "5. Calculate derived metrics (shares, growth rates)\n",
        "6. Save processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
        "\n",
        "from data_loader import save_processed_data, DATA_RAW, DATA_PROCESSED, DATA_REFERENCE\n",
        "from classification_mapper import standardize_country_names, add_historical_period\n",
        "from transformers import (\n",
        "    calculate_country_shares, \n",
        "    calculate_yoy_growth, \n",
        "    adjust_for_inflation,\n",
        "    parse_monthly_columns,\n",
        "    aggregate_monthly_to_annual,\n",
        "    annualize_ytd_value\n",
        ")\n",
        "from usitc_api import USITCDataWebAPI\n",
        "\n",
        "print(\"Modules loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Raw USITC Data Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define file paths\n",
        "usitc_dir = DATA_RAW / 'usitc'\n",
        "\n",
        "imports_file = usitc_dir / 'imports_1995_2024.csv'\n",
        "exports_file = usitc_dir / 'exports_1995_2024.csv'\n",
        "\n",
        "print(f\"Imports file exists: {imports_file.exists()}\")\n",
        "print(f\"Exports file exists: {exports_file.exists()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw wide-format data\n",
        "imports_wide = pd.read_csv(imports_file)\n",
        "exports_wide = pd.read_csv(exports_file)\n",
        "\n",
        "print(f\"Imports: {imports_wide.shape[0]} countries, {imports_wide.shape[1]} columns\")\n",
        "print(f\"Exports: {exports_wide.shape[0]} countries, {exports_wide.shape[1]} columns\")\n",
        "\n",
        "print(\"\\nImports sample:\")\n",
        "display(imports_wide.head())\n",
        "\n",
        "print(\"\\nExports sample:\")\n",
        "display(exports_wide.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1b: Fetch Monthly Data from USITC API (2024-2025)\n",
        "\n",
        "We fetch monthly data for recent years to capture 2025 YTD data that isn't in the annual files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize API client and fetch monthly data for 2024-2025\n",
        "FETCH_FROM_API = True  # Set to False to skip API fetch and use cached files\n",
        "\n",
        "if FETCH_FROM_API:\n",
        "    try:\n",
        "        api = USITCDataWebAPI()\n",
        "        print(\"API client initialized successfully\")\n",
        "        \n",
        "        # Fetch monthly imports\n",
        "        print(\"\\nFetching monthly imports for 2024-2025...\")\n",
        "        monthly_imports_raw = api.get_monthly_imports(start_year=2024, end_year=2025)\n",
        "        print(f\"Retrieved {len(monthly_imports_raw)} rows\")\n",
        "        \n",
        "        # Save raw monthly data\n",
        "        monthly_imports_path = usitc_dir / 'imports_monthly_2024_2025.csv'\n",
        "        monthly_imports_raw.to_csv(monthly_imports_path, index=False)\n",
        "        print(f\"Saved to: {monthly_imports_path}\")\n",
        "        \n",
        "        # Display sample\n",
        "        display(monthly_imports_raw.head())\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"API fetch failed: {e}\")\n",
        "        print(\"Will attempt to load cached monthly data instead.\")\n",
        "        FETCH_FROM_API = False\n",
        "\n",
        "# Load cached monthly data if API fetch was skipped or failed\n",
        "if not FETCH_FROM_API:\n",
        "    monthly_imports_path = usitc_dir / 'imports_monthly_2024_2025.csv'\n",
        "    if monthly_imports_path.exists():\n",
        "        monthly_imports_raw = pd.read_csv(monthly_imports_path)\n",
        "        print(f\"Loaded cached monthly data: {len(monthly_imports_raw)} rows\")\n",
        "        display(monthly_imports_raw.head())\n",
        "    else:\n",
        "        print(\"No cached monthly data found. Run with FETCH_FROM_API=True\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse monthly data to long format and aggregate to annual\n",
        "# The parse_monthly_columns function handles 'Mon YYYY' format columns\n",
        "\n",
        "monthly_imports_long = parse_monthly_columns(monthly_imports_raw)\n",
        "print(f\"Monthly imports (long format): {len(monthly_imports_long)} rows\")\n",
        "print(f\"Months covered: {monthly_imports_long['month'].min()} to {monthly_imports_long['month'].max()}\")\n",
        "print(f\"Years: {monthly_imports_long['year'].unique()}\")\n",
        "\n",
        "display(monthly_imports_long.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate monthly to annual totals\n",
        "monthly_imports_annual = aggregate_monthly_to_annual(monthly_imports_long)\n",
        "print(f\"Aggregated to {len(monthly_imports_annual)} country-year records\")\n",
        "\n",
        "# Show 2025 YTD status\n",
        "ytd_2025 = monthly_imports_annual[monthly_imports_annual['year'] == 2025]\n",
        "print(f\"\\n2025 YTD data: {len(ytd_2025)} countries\")\n",
        "print(f\"Months of 2025 data: {ytd_2025['month_count'].max() if len(ytd_2025) > 0 else 'N/A'}\")\n",
        "print(f\"Last month: {ytd_2025['last_month'].max() if len(ytd_2025) > 0 else 'N/A'}\")\n",
        "\n",
        "display(monthly_imports_annual[monthly_imports_annual['year'] == 2025].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare monthly data for merging with historical annual data\n",
        "# Add trade_type column and format value\n",
        "monthly_imports_annual['trade_type'] = 'import'\n",
        "\n",
        "# Determine scaling: USITC API returns values in billions\n",
        "# Convert to actual USD to match historical data\n",
        "monthly_imports_annual['value'] = monthly_imports_annual['value'] * 1e9\n",
        "\n",
        "# Keep only columns needed for merge\n",
        "monthly_for_merge = monthly_imports_annual[['country', 'year', 'value', 'trade_type', 'is_ytd', 'month_count', 'last_month']].copy()\n",
        "\n",
        "print(f\"Monthly data ready for merge: {len(monthly_for_merge)} records\")\n",
        "display(monthly_for_merge[monthly_for_merge['year'] == 2025].nlargest(10, 'value'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Transform from Wide to Long Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wide_to_long(df_wide: pd.DataFrame, trade_type: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Transform USITC wide-format data to long format.\n",
        "    \n",
        "    Args:\n",
        "        df_wide: DataFrame with Country column and year columns (1995, 1996, ...)\n",
        "        trade_type: 'import' or 'export'\n",
        "    \n",
        "    Returns:\n",
        "        Long-format DataFrame with columns: country, year, value, trade_type\n",
        "    \"\"\"\n",
        "    # Get the country column name (first column)\n",
        "    country_col = df_wide.columns[0]\n",
        "    \n",
        "    # Get year columns (all numeric column names)\n",
        "    year_cols = [c for c in df_wide.columns[1:] if str(c).replace('.', '').isdigit()]\n",
        "    \n",
        "    # Filter to only country and year columns\n",
        "    df_subset = df_wide[[country_col] + year_cols].copy()\n",
        "    \n",
        "    # Melt from wide to long\n",
        "    df_long = df_subset.melt(\n",
        "        id_vars=[country_col],\n",
        "        var_name='year',\n",
        "        value_name='value'\n",
        "    )\n",
        "    \n",
        "    # Rename country column\n",
        "    df_long = df_long.rename(columns={country_col: 'country'})\n",
        "    \n",
        "    # Add trade type\n",
        "    df_long['trade_type'] = trade_type\n",
        "    \n",
        "    # Convert year to integer\n",
        "    df_long['year'] = df_long['year'].astype(int)\n",
        "    \n",
        "    # Convert value to numeric (handle any formatting issues)\n",
        "    df_long['value'] = pd.to_numeric(\n",
        "        df_long['value'].astype(str).str.replace(',', '').str.replace('\"', ''),\n",
        "        errors='coerce'\n",
        "    )\n",
        "    \n",
        "    # Filter out Total row and other non-country rows\n",
        "    exclude_rows = ['Total:', 'Total', 'Unspecified', 'Transshipment', 'Internat Organization']\n",
        "    df_long = df_long[~df_long['country'].str.strip().isin(exclude_rows)]\n",
        "    \n",
        "    # Convert from billions to actual USD\n",
        "    df_long['value'] = df_long['value'] * 1e9\n",
        "    \n",
        "    return df_long\n",
        "\n",
        "# Transform both datasets\n",
        "imports_long = wide_to_long(imports_wide, 'import')\n",
        "exports_long = wide_to_long(exports_wide, 'export')\n",
        "\n",
        "print(f\"Imports (long): {len(imports_long):,} rows\")\n",
        "print(f\"Exports (long): {len(exports_long):,} rows\")\n",
        "\n",
        "print(\"\\nImports sample:\")\n",
        "display(imports_long.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine imports and exports into single DataFrame\n",
        "trade_df = pd.concat([imports_long, exports_long], ignore_index=True)\n",
        "\n",
        "# Add is_ytd flag (False for all historical annual data)\n",
        "trade_df['is_ytd'] = False\n",
        "trade_df['month_count'] = 12\n",
        "trade_df['last_month'] = 12\n",
        "\n",
        "print(f\"Historical dataset: {len(trade_df):,} rows\")\n",
        "print(f\"Year range: {trade_df['year'].min()} - {trade_df['year'].max()}\")\n",
        "\n",
        "# Filter historical data to years before the API data starts\n",
        "# We'll use API data for 2024-2025 to get the most recent data\n",
        "historical_cutoff = 2023\n",
        "trade_df_historical = trade_df[trade_df['year'] <= historical_cutoff].copy()\n",
        "print(f\"\\nHistorical data (up to {historical_cutoff}): {len(trade_df_historical):,} rows\")\n",
        "\n",
        "# Merge with monthly API data (2024-2025)\n",
        "if 'monthly_for_merge' in dir() and len(monthly_for_merge) > 0:\n",
        "    print(f\"\\nMerging with API data: {len(monthly_for_merge):,} rows\")\n",
        "    trade_df = pd.concat([trade_df_historical, monthly_for_merge], ignore_index=True)\n",
        "    print(f\"Combined dataset: {len(trade_df):,} rows\")\n",
        "else:\n",
        "    print(\"\\nNo API data to merge - using only historical data\")\n",
        "    trade_df = trade_df_historical\n",
        "\n",
        "print(f\"\\nTrade type distribution:\")\n",
        "print(trade_df['trade_type'].value_counts())\n",
        "\n",
        "print(f\"\\nFinal year range: {trade_df['year'].min()} - {trade_df['year'].max()}\")\n",
        "print(f\"Unique countries: {trade_df['country'].nunique()}\")\n",
        "\n",
        "# Show 2025 data summary\n",
        "if 2025 in trade_df['year'].values:\n",
        "    ytd_info = trade_df[trade_df['year'] == 2025].iloc[0]\n",
        "    print(f\"\\n2025 data: YTD through month {ytd_info['last_month']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Standardize Country Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply country name standardization\n",
        "trade_df = standardize_country_names(trade_df, country_col='country')\n",
        "\n",
        "print(f\"Unique countries after standardization: {trade_df['country'].nunique()}\")\n",
        "\n",
        "# Show top countries by total trade value\n",
        "top_countries = trade_df.groupby('country')['value'].sum().sort_values(ascending=False).head(20)\n",
        "print(\"\\nTop 20 trading partners (total trade 1995-2024):\")\n",
        "for i, (country, value) in enumerate(top_countries.items(), 1):\n",
        "    print(f\"  {i:2}. {country}: ${value/1e12:.2f} trillion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Apply Inflation Adjustment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load GDP deflator\n",
        "deflator_df = pd.read_csv(DATA_REFERENCE / 'gdp_deflator.csv')\n",
        "print(f\"GDP Deflator loaded: {len(deflator_df)} years\")\n",
        "display(deflator_df.tail(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply inflation adjustment (base year 2020)\n",
        "trade_df = adjust_for_inflation(\n",
        "    trade_df,\n",
        "    deflator_df,\n",
        "    value_col='value',\n",
        "    year_col='year',\n",
        "    base_year=2020\n",
        ")\n",
        "\n",
        "print(\"Sample with real values:\")\n",
        "sample = trade_df[trade_df['country'] == 'China'].sort_values('year')\n",
        "display(sample[['year', 'country', 'trade_type', 'value', 'value_real']].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Calculate Derived Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate country shares (% of total trade by year and trade type)\n",
        "trade_df = calculate_country_shares(\n",
        "    trade_df,\n",
        "    value_col='value_real',\n",
        "    country_col='country',\n",
        "    year_col='year',\n",
        "    trade_type_col='trade_type'\n",
        ")\n",
        "\n",
        "# Show top import sources for the most recent year\n",
        "latest_year = trade_df['year'].max()\n",
        "imports_latest = trade_df[(trade_df['year'] == latest_year) & (trade_df['trade_type'] == 'import')]\n",
        "imports_latest_top = imports_latest.nlargest(10, 'share_pct')[['country', 'value_real', 'share_pct']]\n",
        "\n",
        "# Check if latest year is YTD\n",
        "is_ytd = imports_latest['is_ytd'].iloc[0] if 'is_ytd' in imports_latest.columns else False\n",
        "ytd_note = \" (YTD)\" if is_ytd else \"\"\n",
        "print(f\"Top import sources in {latest_year}{ytd_note} (by share):\")\n",
        "display(imports_latest_top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate year-over-year growth rates\n",
        "trade_df = calculate_yoy_growth(\n",
        "    trade_df,\n",
        "    value_col='value_real',\n",
        "    country_col='country',\n",
        "    year_col='year',\n",
        "    trade_type_col='trade_type'\n",
        ")\n",
        "\n",
        "print(\"China import growth over time:\")\n",
        "china_imports = trade_df[(trade_df['country'] == 'China') & (trade_df['trade_type'] == 'import')].sort_values('year')\n",
        "display(china_imports[['year', 'value_real', 'share_pct', 'yoy_growth_pct']].tail(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add historical period classification\n",
        "trade_df = add_historical_period(trade_df, year_col='year')\n",
        "\n",
        "print(\"Historical periods in data:\")\n",
        "print(trade_df.groupby('period')['year'].agg(['min', 'max', 'count']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final columns\n",
        "print(\"Final columns:\")\n",
        "print(trade_df.columns.tolist())\n",
        "\n",
        "print(f\"\\nFinal dataset shape: {trade_df.shape}\")\n",
        "print(f\"Memory usage: {trade_df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Data Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values:\")\n",
        "print(trade_df.isnull().sum())\n",
        "\n",
        "# Check for negative values\n",
        "print(f\"\\nNegative trade values: {(trade_df['value'] < 0).sum()}\")\n",
        "\n",
        "# Check year coverage\n",
        "print(f\"\\nYears covered: {sorted(trade_df['year'].unique())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify total trade roughly matches known values\n",
        "print(\"Total US imports by year (billions USD, nominal):\")\n",
        "annual_imports = trade_df[trade_df['trade_type'] == 'import'].groupby('year')['value'].sum() / 1e9\n",
        "print(annual_imports.tail(10).round(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Save Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure output directory exists\n",
        "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Determine output filename based on data coverage\n",
        "max_year = trade_df['year'].max()\n",
        "output_filename = f'trade_data_1995_{max_year}.csv'\n",
        "output_file = DATA_PROCESSED / output_filename\n",
        "\n",
        "# Save combined processed data\n",
        "trade_df.to_csv(output_file, index=False)\n",
        "print(f\"Saved processed data to: {output_file}\")\n",
        "print(f\"File size: {output_file.stat().st_size / 1e6:.1f} MB\")\n",
        "\n",
        "# Check for YTD data\n",
        "if trade_df['is_ytd'].any():\n",
        "    ytd_years = trade_df[trade_df['is_ytd']]['year'].unique()\n",
        "    for year in ytd_years:\n",
        "        ytd_info = trade_df[(trade_df['year'] == year) & (trade_df['is_ytd'])].iloc[0]\n",
        "        print(f\"\\nNote: {year} data is YTD through month {ytd_info['last_month']}\")\n",
        "\n",
        "# Also save separate imports and exports files\n",
        "imports_processed = trade_df[trade_df['trade_type'] == 'import']\n",
        "exports_processed = trade_df[trade_df['trade_type'] == 'export']\n",
        "\n",
        "imports_processed.to_csv(DATA_PROCESSED / 'imports_processed.csv', index=False)\n",
        "exports_processed.to_csv(DATA_PROCESSED / 'exports_processed.csv', index=False)\n",
        "\n",
        "print(f\"\\nSaved {len(imports_processed):,} import records\")\n",
        "print(f\"Saved {len(exports_processed):,} export records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"DATA PROCESSING COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTotal records: {len(trade_df):,}\")\n",
        "print(f\"Years: {trade_df['year'].min()} - {trade_df['year'].max()}\")\n",
        "print(f\"Countries: {trade_df['country'].nunique()}\")\n",
        "print(f\"Trade types: {trade_df['trade_type'].unique().tolist()}\")\n",
        "\n",
        "# Report YTD status\n",
        "if trade_df['is_ytd'].any():\n",
        "    print(f\"\\nYTD data included:\")\n",
        "    for year in trade_df[trade_df['is_ytd']]['year'].unique():\n",
        "        ytd_row = trade_df[(trade_df['year'] == year) & (trade_df['is_ytd'])].iloc[0]\n",
        "        print(f\"  - {year}: Through month {ytd_row['last_month']} ({ytd_row['month_count']} months)\")\n",
        "\n",
        "print(f\"\\nOutput files:\")\n",
        "print(f\"  - {output_file}\")\n",
        "print(f\"  - {DATA_PROCESSED / 'imports_processed.csv'}\")\n",
        "print(f\"  - {DATA_PROCESSED / 'exports_processed.csv'}\")\n",
        "print(\"\\n-> Proceed to 03_exploratory_analysis.ipynb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End of notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
